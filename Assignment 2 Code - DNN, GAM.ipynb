{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e60fec1",
   "metadata": {},
   "source": [
    "# Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af2c93d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 23:05:28.570644: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pygam import LogisticGAM, s, f\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "8cdf3844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b7039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'\n",
    "column_names = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \n",
    "                \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \n",
    "                \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\", \n",
    "                \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\", \"word_freq_free\", \n",
    "                \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\", \n",
    "                \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \n",
    "                \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \n",
    "                \"word_freq_telnet\", \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \n",
    "                \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\", \n",
    "                \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \n",
    "                \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \n",
    "                \"char_freq_(\", \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_#\", \n",
    "                \"capital_run_length_average\", \"capital_run_length_longest\", \"capital_run_length_total\", \"Spam\"]\n",
    "\n",
    "data = pd.read_csv(url, names=column_names, sep=',',skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7be85ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                0\n",
       "word_freq_address             0\n",
       "word_freq_all                 0\n",
       "word_freq_3d                  0\n",
       "word_freq_our                 0\n",
       "word_freq_over                0\n",
       "word_freq_remove              0\n",
       "word_freq_internet            0\n",
       "word_freq_order               0\n",
       "word_freq_mail                0\n",
       "word_freq_receive             0\n",
       "word_freq_will                0\n",
       "word_freq_people              0\n",
       "word_freq_report              0\n",
       "word_freq_addresses           0\n",
       "word_freq_free                0\n",
       "word_freq_business            0\n",
       "word_freq_email               0\n",
       "word_freq_you                 0\n",
       "word_freq_credit              0\n",
       "word_freq_your                0\n",
       "word_freq_font                0\n",
       "word_freq_000                 0\n",
       "word_freq_money               0\n",
       "word_freq_hp                  0\n",
       "word_freq_hpl                 0\n",
       "word_freq_george              0\n",
       "word_freq_650                 0\n",
       "word_freq_lab                 0\n",
       "word_freq_labs                0\n",
       "word_freq_telnet              0\n",
       "word_freq_857                 0\n",
       "word_freq_data                0\n",
       "word_freq_415                 0\n",
       "word_freq_85                  0\n",
       "word_freq_technology          0\n",
       "word_freq_1999                0\n",
       "word_freq_parts               0\n",
       "word_freq_pm                  0\n",
       "word_freq_direct              0\n",
       "word_freq_cs                  0\n",
       "word_freq_meeting             0\n",
       "word_freq_original            0\n",
       "word_freq_project             0\n",
       "word_freq_re                  0\n",
       "word_freq_edu                 0\n",
       "word_freq_table               0\n",
       "word_freq_conference          0\n",
       "char_freq_;                   0\n",
       "char_freq_(                   0\n",
       "char_freq_[                   0\n",
       "char_freq_!                   0\n",
       "char_freq_$                   0\n",
       "char_freq_#                   0\n",
       "capital_run_length_average    0\n",
       "capital_run_length_longest    0\n",
       "capital_run_length_total      0\n",
       "Spam                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8db255ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into training and testing data\n",
    "training_data, testing_data = train_test_split(data, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f01f9bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = training_data.copy()\n",
    "training_classes = training_features.pop('Spam')\n",
    "testing_features = testing_data.copy()\n",
    "testing_classes = testing_features.pop('Spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5a7c90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_freq_make</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.305358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_address</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_all</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>5.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_3d</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>42.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_our</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.380</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_over</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_remove</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_internet</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_order</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_mail</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.160</td>\n",
       "      <td>18.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_receive</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.059824</td>\n",
       "      <td>0.201545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_will</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.541702</td>\n",
       "      <td>0.861698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.800</td>\n",
       "      <td>9.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_people</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.093930</td>\n",
       "      <td>0.301036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_report</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.058626</td>\n",
       "      <td>0.335184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_addresses</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.049205</td>\n",
       "      <td>0.258843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_free</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.248848</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_business</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.142586</td>\n",
       "      <td>0.444055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_email</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.184745</td>\n",
       "      <td>0.531122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_you</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>1.662100</td>\n",
       "      <td>1.775481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.310</td>\n",
       "      <td>2.640</td>\n",
       "      <td>18.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_credit</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.085577</td>\n",
       "      <td>0.509767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_your</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.809761</td>\n",
       "      <td>1.200810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.220</td>\n",
       "      <td>1.270</td>\n",
       "      <td>11.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_font</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.121202</td>\n",
       "      <td>1.025756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_000</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.101645</td>\n",
       "      <td>0.350286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_money</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.094269</td>\n",
       "      <td>0.442636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_hp</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.549504</td>\n",
       "      <td>1.671349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_hpl</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.265384</td>\n",
       "      <td>0.886955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_george</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.767305</td>\n",
       "      <td>3.367292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>33.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_650</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.124845</td>\n",
       "      <td>0.538576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_lab</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.098915</td>\n",
       "      <td>0.593327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_labs</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.102852</td>\n",
       "      <td>0.456682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_telnet</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.064753</td>\n",
       "      <td>0.403393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_857</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.047048</td>\n",
       "      <td>0.328559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_data</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.097229</td>\n",
       "      <td>0.555907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_415</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.047835</td>\n",
       "      <td>0.329445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_85</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.105412</td>\n",
       "      <td>0.532260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_technology</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.402623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_1999</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.136953</td>\n",
       "      <td>0.423451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_parts</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.220651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_pm</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.078629</td>\n",
       "      <td>0.434672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_direct</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.064834</td>\n",
       "      <td>0.349916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_cs</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.043667</td>\n",
       "      <td>0.361205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_meeting</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.132339</td>\n",
       "      <td>0.766819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_original</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.046099</td>\n",
       "      <td>0.223812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_project</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.079196</td>\n",
       "      <td>0.621976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_re</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.301224</td>\n",
       "      <td>1.011687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.110</td>\n",
       "      <td>21.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_edu</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.179824</td>\n",
       "      <td>0.911119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_table</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.076274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_conference</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.285735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_;</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_(</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.188</td>\n",
       "      <td>9.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_[</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_!</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>32.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_$</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>6.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_#</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>19.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.588</td>\n",
       "      <td>2.276</td>\n",
       "      <td>3.706</td>\n",
       "      <td>1102.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>9989.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.000</td>\n",
       "      <td>95.000</td>\n",
       "      <td>266.000</td>\n",
       "      <td>15841.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spam</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.394045</td>\n",
       "      <td>0.488698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count        mean         std  min     25%  \\\n",
       "word_freq_make              4601.0    0.104553    0.305358  0.0   0.000   \n",
       "word_freq_address           4601.0    0.213015    1.290575  0.0   0.000   \n",
       "word_freq_all               4601.0    0.280656    0.504143  0.0   0.000   \n",
       "word_freq_3d                4601.0    0.065425    1.395151  0.0   0.000   \n",
       "word_freq_our               4601.0    0.312223    0.672513  0.0   0.000   \n",
       "word_freq_over              4601.0    0.095901    0.273824  0.0   0.000   \n",
       "word_freq_remove            4601.0    0.114208    0.391441  0.0   0.000   \n",
       "word_freq_internet          4601.0    0.105295    0.401071  0.0   0.000   \n",
       "word_freq_order             4601.0    0.090067    0.278616  0.0   0.000   \n",
       "word_freq_mail              4601.0    0.239413    0.644755  0.0   0.000   \n",
       "word_freq_receive           4601.0    0.059824    0.201545  0.0   0.000   \n",
       "word_freq_will              4601.0    0.541702    0.861698  0.0   0.000   \n",
       "word_freq_people            4601.0    0.093930    0.301036  0.0   0.000   \n",
       "word_freq_report            4601.0    0.058626    0.335184  0.0   0.000   \n",
       "word_freq_addresses         4601.0    0.049205    0.258843  0.0   0.000   \n",
       "word_freq_free              4601.0    0.248848    0.825792  0.0   0.000   \n",
       "word_freq_business          4601.0    0.142586    0.444055  0.0   0.000   \n",
       "word_freq_email             4601.0    0.184745    0.531122  0.0   0.000   \n",
       "word_freq_you               4601.0    1.662100    1.775481  0.0   0.000   \n",
       "word_freq_credit            4601.0    0.085577    0.509767  0.0   0.000   \n",
       "word_freq_your              4601.0    0.809761    1.200810  0.0   0.000   \n",
       "word_freq_font              4601.0    0.121202    1.025756  0.0   0.000   \n",
       "word_freq_000               4601.0    0.101645    0.350286  0.0   0.000   \n",
       "word_freq_money             4601.0    0.094269    0.442636  0.0   0.000   \n",
       "word_freq_hp                4601.0    0.549504    1.671349  0.0   0.000   \n",
       "word_freq_hpl               4601.0    0.265384    0.886955  0.0   0.000   \n",
       "word_freq_george            4601.0    0.767305    3.367292  0.0   0.000   \n",
       "word_freq_650               4601.0    0.124845    0.538576  0.0   0.000   \n",
       "word_freq_lab               4601.0    0.098915    0.593327  0.0   0.000   \n",
       "word_freq_labs              4601.0    0.102852    0.456682  0.0   0.000   \n",
       "word_freq_telnet            4601.0    0.064753    0.403393  0.0   0.000   \n",
       "word_freq_857               4601.0    0.047048    0.328559  0.0   0.000   \n",
       "word_freq_data              4601.0    0.097229    0.555907  0.0   0.000   \n",
       "word_freq_415               4601.0    0.047835    0.329445  0.0   0.000   \n",
       "word_freq_85                4601.0    0.105412    0.532260  0.0   0.000   \n",
       "word_freq_technology        4601.0    0.097477    0.402623  0.0   0.000   \n",
       "word_freq_1999              4601.0    0.136953    0.423451  0.0   0.000   \n",
       "word_freq_parts             4601.0    0.013201    0.220651  0.0   0.000   \n",
       "word_freq_pm                4601.0    0.078629    0.434672  0.0   0.000   \n",
       "word_freq_direct            4601.0    0.064834    0.349916  0.0   0.000   \n",
       "word_freq_cs                4601.0    0.043667    0.361205  0.0   0.000   \n",
       "word_freq_meeting           4601.0    0.132339    0.766819  0.0   0.000   \n",
       "word_freq_original          4601.0    0.046099    0.223812  0.0   0.000   \n",
       "word_freq_project           4601.0    0.079196    0.621976  0.0   0.000   \n",
       "word_freq_re                4601.0    0.301224    1.011687  0.0   0.000   \n",
       "word_freq_edu               4601.0    0.179824    0.911119  0.0   0.000   \n",
       "word_freq_table             4601.0    0.005444    0.076274  0.0   0.000   \n",
       "word_freq_conference        4601.0    0.031869    0.285735  0.0   0.000   \n",
       "char_freq_;                 4601.0    0.038575    0.243471  0.0   0.000   \n",
       "char_freq_(                 4601.0    0.139030    0.270355  0.0   0.000   \n",
       "char_freq_[                 4601.0    0.016976    0.109394  0.0   0.000   \n",
       "char_freq_!                 4601.0    0.269071    0.815672  0.0   0.000   \n",
       "char_freq_$                 4601.0    0.075811    0.245882  0.0   0.000   \n",
       "char_freq_#                 4601.0    0.044238    0.429342  0.0   0.000   \n",
       "capital_run_length_average  4601.0    5.191515   31.729449  1.0   1.588   \n",
       "capital_run_length_longest  4601.0   52.172789  194.891310  1.0   6.000   \n",
       "capital_run_length_total    4601.0  283.289285  606.347851  1.0  35.000   \n",
       "Spam                        4601.0    0.394045    0.488698  0.0   0.000   \n",
       "\n",
       "                               50%      75%        max  \n",
       "word_freq_make               0.000    0.000      4.540  \n",
       "word_freq_address            0.000    0.000     14.280  \n",
       "word_freq_all                0.000    0.420      5.100  \n",
       "word_freq_3d                 0.000    0.000     42.810  \n",
       "word_freq_our                0.000    0.380     10.000  \n",
       "word_freq_over               0.000    0.000      5.880  \n",
       "word_freq_remove             0.000    0.000      7.270  \n",
       "word_freq_internet           0.000    0.000     11.110  \n",
       "word_freq_order              0.000    0.000      5.260  \n",
       "word_freq_mail               0.000    0.160     18.180  \n",
       "word_freq_receive            0.000    0.000      2.610  \n",
       "word_freq_will               0.100    0.800      9.670  \n",
       "word_freq_people             0.000    0.000      5.550  \n",
       "word_freq_report             0.000    0.000     10.000  \n",
       "word_freq_addresses          0.000    0.000      4.410  \n",
       "word_freq_free               0.000    0.100     20.000  \n",
       "word_freq_business           0.000    0.000      7.140  \n",
       "word_freq_email              0.000    0.000      9.090  \n",
       "word_freq_you                1.310    2.640     18.750  \n",
       "word_freq_credit             0.000    0.000     18.180  \n",
       "word_freq_your               0.220    1.270     11.110  \n",
       "word_freq_font               0.000    0.000     17.100  \n",
       "word_freq_000                0.000    0.000      5.450  \n",
       "word_freq_money              0.000    0.000     12.500  \n",
       "word_freq_hp                 0.000    0.000     20.830  \n",
       "word_freq_hpl                0.000    0.000     16.660  \n",
       "word_freq_george             0.000    0.000     33.330  \n",
       "word_freq_650                0.000    0.000      9.090  \n",
       "word_freq_lab                0.000    0.000     14.280  \n",
       "word_freq_labs               0.000    0.000      5.880  \n",
       "word_freq_telnet             0.000    0.000     12.500  \n",
       "word_freq_857                0.000    0.000      4.760  \n",
       "word_freq_data               0.000    0.000     18.180  \n",
       "word_freq_415                0.000    0.000      4.760  \n",
       "word_freq_85                 0.000    0.000     20.000  \n",
       "word_freq_technology         0.000    0.000      7.690  \n",
       "word_freq_1999               0.000    0.000      6.890  \n",
       "word_freq_parts              0.000    0.000      8.330  \n",
       "word_freq_pm                 0.000    0.000     11.110  \n",
       "word_freq_direct             0.000    0.000      4.760  \n",
       "word_freq_cs                 0.000    0.000      7.140  \n",
       "word_freq_meeting            0.000    0.000     14.280  \n",
       "word_freq_original           0.000    0.000      3.570  \n",
       "word_freq_project            0.000    0.000     20.000  \n",
       "word_freq_re                 0.000    0.110     21.420  \n",
       "word_freq_edu                0.000    0.000     22.050  \n",
       "word_freq_table              0.000    0.000      2.170  \n",
       "word_freq_conference         0.000    0.000     10.000  \n",
       "char_freq_;                  0.000    0.000      4.385  \n",
       "char_freq_(                  0.065    0.188      9.752  \n",
       "char_freq_[                  0.000    0.000      4.081  \n",
       "char_freq_!                  0.000    0.315     32.478  \n",
       "char_freq_$                  0.000    0.052      6.003  \n",
       "char_freq_#                  0.000    0.000     19.829  \n",
       "capital_run_length_average   2.276    3.706   1102.500  \n",
       "capital_run_length_longest  15.000   43.000   9989.000  \n",
       "capital_run_length_total    95.000  266.000  15841.000  \n",
       "Spam                         0.000    1.000      1.000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d811e7a",
   "metadata": {},
   "source": [
    "# Deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "76b55105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_123 (Dense)           (None, 36)                2088      \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,305\n",
      "Trainable params: 3,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#58 input variables so 58 input neurons?\n",
    "#1 output for the set of inputs so 1 output neuron\n",
    "#hidden layers?\n",
    "\n",
    "#specify optimiser such as nesterov momentum?\n",
    "\n",
    "dnn_spam_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape = (57)),\n",
    "    layers.Dense(36, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "#sigmoid outputs between 0 and 1 which is perfect for probabilities\n",
    "\n",
    "dnn_spam_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "aec3281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam optimiser for advanced gradient descent, loss is binary cross entropy since binary classification\n",
    "#problem\n",
    "random.seed(5)\n",
    "dnn_spam_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                  loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics = [tf.keras.metrics.BinaryAccuracy(name = 'acc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "2bf73501",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "92/92 [==============================] - 1s 3ms/step - loss: 8.2329 - acc: 0.6736 - val_loss: 0.9144 - val_acc: 0.7812\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 5.1279 - acc: 0.7245 - val_loss: 0.4095 - val_acc: 0.8220\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.1238 - acc: 0.7310 - val_loss: 1.1228 - val_acc: 0.7310\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.2124 - acc: 0.7340 - val_loss: 1.1649 - val_acc: 0.6970\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9790 - acc: 0.7670 - val_loss: 0.3703 - val_acc: 0.8125\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.1198 - acc: 0.7748 - val_loss: 0.2979 - val_acc: 0.8601\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8724 - acc: 0.7775 - val_loss: 0.3528 - val_acc: 0.8533\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.0669 - acc: 0.7619 - val_loss: 0.3460 - val_acc: 0.8560\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7719 - acc: 0.7765 - val_loss: 0.3530 - val_acc: 0.8315\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8938 - acc: 0.7802 - val_loss: 1.2691 - val_acc: 0.6902\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7688 - acc: 0.7653 - val_loss: 0.4441 - val_acc: 0.8016\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.1763 - acc: 0.7636 - val_loss: 0.4427 - val_acc: 0.8057\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.6832 - acc: 0.8060 - val_loss: 0.3542 - val_acc: 0.8492\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.6747 - acc: 0.8234 - val_loss: 0.3561 - val_acc: 0.8533\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5806 - acc: 0.8427 - val_loss: 0.3684 - val_acc: 0.8465\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.6328 - acc: 0.8376 - val_loss: 0.2846 - val_acc: 0.8804\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7162 - acc: 0.8176 - val_loss: 0.6777 - val_acc: 0.7948\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.6732 - acc: 0.7877 - val_loss: 0.2983 - val_acc: 0.8641\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9050 - acc: 0.7663 - val_loss: 0.3949 - val_acc: 0.7935\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7377 - acc: 0.8156 - val_loss: 0.4065 - val_acc: 0.7935\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5568 - acc: 0.8516 - val_loss: 0.3792 - val_acc: 0.8383\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5299 - acc: 0.8641 - val_loss: 0.2927 - val_acc: 0.8723\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5377 - acc: 0.8645 - val_loss: 0.3961 - val_acc: 0.8424\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5843 - acc: 0.8638 - val_loss: 0.3379 - val_acc: 0.8723\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5527 - acc: 0.8526 - val_loss: 0.4757 - val_acc: 0.8207\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5975 - acc: 0.8342 - val_loss: 0.2795 - val_acc: 0.8764\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5227 - acc: 0.8635 - val_loss: 0.3187 - val_acc: 0.8886\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.6420 - acc: 0.8471 - val_loss: 0.2531 - val_acc: 0.8954\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5751 - acc: 0.8478 - val_loss: 0.2917 - val_acc: 0.8804\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.4883 - acc: 0.8624 - val_loss: 0.2791 - val_acc: 0.8859\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4462 - acc: 0.8774 - val_loss: 0.2698 - val_acc: 0.9117\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4644 - acc: 0.8713 - val_loss: 0.2892 - val_acc: 0.8872\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4317 - acc: 0.8950 - val_loss: 0.2967 - val_acc: 0.8832\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4501 - acc: 0.8781 - val_loss: 0.2741 - val_acc: 0.8940\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5248 - acc: 0.8431 - val_loss: 0.3587 - val_acc: 0.8492\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.6318 - acc: 0.8448 - val_loss: 0.4556 - val_acc: 0.7269\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7324 - acc: 0.7344 - val_loss: 0.3179 - val_acc: 0.8424\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5684 - acc: 0.8407 - val_loss: 0.5362 - val_acc: 0.8179\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5040 - acc: 0.8821 - val_loss: 0.3147 - val_acc: 0.8899\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4893 - acc: 0.8838 - val_loss: 0.3408 - val_acc: 0.8641\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5312 - acc: 0.8685 - val_loss: 0.2453 - val_acc: 0.9293\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4711 - acc: 0.8832 - val_loss: 0.2731 - val_acc: 0.9035\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4227 - acc: 0.9018 - val_loss: 0.2825 - val_acc: 0.9008\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4656 - acc: 0.8791 - val_loss: 0.2780 - val_acc: 0.8995\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5104 - acc: 0.8886 - val_loss: 0.2492 - val_acc: 0.9293\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.6565 - acc: 0.8247 - val_loss: 0.3544 - val_acc: 0.8723\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5266 - acc: 0.8750 - val_loss: 0.2793 - val_acc: 0.9008\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7706 - acc: 0.8845 - val_loss: 0.3790 - val_acc: 0.8125\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5004 - acc: 0.8611 - val_loss: 0.2816 - val_acc: 0.9062\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5172 - acc: 0.8546 - val_loss: 0.2520 - val_acc: 0.9253\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4119 - acc: 0.8937 - val_loss: 0.3030 - val_acc: 0.8899\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.4427 - acc: 0.8906 - val_loss: 0.2649 - val_acc: 0.9158\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4151 - acc: 0.8910 - val_loss: 0.2545 - val_acc: 0.9212\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5027 - acc: 0.8723 - val_loss: 0.2633 - val_acc: 0.9171\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4435 - acc: 0.8886 - val_loss: 0.2958 - val_acc: 0.8995\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4281 - acc: 0.8950 - val_loss: 0.2368 - val_acc: 0.9226\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3672 - acc: 0.9032 - val_loss: 0.2507 - val_acc: 0.9198\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3976 - acc: 0.8984 - val_loss: 0.2513 - val_acc: 0.9266\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.4628 - acc: 0.8750 - val_loss: 0.3197 - val_acc: 0.8560\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.4908 - acc: 0.8753 - val_loss: 0.3207 - val_acc: 0.8505\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.4647 - acc: 0.8777 - val_loss: 0.2668 - val_acc: 0.9171\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.7844 - acc: 0.8448 - val_loss: 0.2613 - val_acc: 0.9117\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5139 - acc: 0.8838 - val_loss: 0.3578 - val_acc: 0.8696\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3955 - acc: 0.8961 - val_loss: 0.2900 - val_acc: 0.9049\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3660 - acc: 0.9039 - val_loss: 0.2785 - val_acc: 0.9117\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3972 - acc: 0.9086 - val_loss: 0.2686 - val_acc: 0.9090\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3647 - acc: 0.9090 - val_loss: 0.2859 - val_acc: 0.9158\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3446 - acc: 0.9151 - val_loss: 0.2702 - val_acc: 0.9253\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4130 - acc: 0.8859 - val_loss: 0.3262 - val_acc: 0.8832\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7003 - acc: 0.8247 - val_loss: 0.4471 - val_acc: 0.7894\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.4710 - acc: 0.8910 - val_loss: 0.2702 - val_acc: 0.9130\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.4162 - acc: 0.8978 - val_loss: 0.2400 - val_acc: 0.9389\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3200 - acc: 0.9243 - val_loss: 0.3156 - val_acc: 0.9049\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3693 - acc: 0.9056 - val_loss: 0.2876 - val_acc: 0.9212\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3256 - acc: 0.9171 - val_loss: 0.3013 - val_acc: 0.9226\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5351 - acc: 0.8247 - val_loss: 0.5883 - val_acc: 0.7541\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.6571 - acc: 0.7765 - val_loss: 0.3146 - val_acc: 0.9361\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5291 - acc: 0.8543 - val_loss: 0.3586 - val_acc: 0.8845\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3594 - acc: 0.9025 - val_loss: 0.2949 - val_acc: 0.9266\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5466 - acc: 0.8784 - val_loss: 0.4367 - val_acc: 0.8098\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5820 - acc: 0.8410 - val_loss: 0.2960 - val_acc: 0.9008\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5290 - acc: 0.8631 - val_loss: 0.3175 - val_acc: 0.8995\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3559 - acc: 0.9175 - val_loss: 0.2680 - val_acc: 0.9348\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3370 - acc: 0.9226 - val_loss: 0.3000 - val_acc: 0.9117\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3183 - acc: 0.9270 - val_loss: 0.2800 - val_acc: 0.9361\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.2890 - acc: 0.9334 - val_loss: 0.2749 - val_acc: 0.9348\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4419 - acc: 0.8828 - val_loss: 0.4391 - val_acc: 0.8587\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8540 - acc: 0.7711 - val_loss: 0.4301 - val_acc: 0.8410\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.6046 - acc: 0.7993 - val_loss: 0.3824 - val_acc: 0.8859\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5380 - acc: 0.8179 - val_loss: 0.3885 - val_acc: 0.8505\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4444 - acc: 0.8808 - val_loss: 0.3443 - val_acc: 0.8696\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4656 - acc: 0.9039 - val_loss: 0.4297 - val_acc: 0.8954\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3753 - acc: 0.9181 - val_loss: 0.2899 - val_acc: 0.8995\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3380 - acc: 0.9239 - val_loss: 0.3057 - val_acc: 0.9334\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.2950 - acc: 0.9361 - val_loss: 0.3235 - val_acc: 0.9158\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3369 - acc: 0.9236 - val_loss: 0.3949 - val_acc: 0.8995\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3954 - acc: 0.8991 - val_loss: 0.3414 - val_acc: 0.9198\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3265 - acc: 0.9229 - val_loss: 0.3351 - val_acc: 0.9334\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3638 - acc: 0.9120 - val_loss: 0.3846 - val_acc: 0.9090\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3361 - acc: 0.9253 - val_loss: 0.4434 - val_acc: 0.8967\n"
     ]
    }
   ],
   "source": [
    "#fit model with 100 epochs\n",
    "dnn_fit = dnn_spam_model.fit(x= training_features, \n",
    "               y= training_classes, \n",
    "               epochs = 100, \n",
    "               validation_split = 0.2,\n",
    "               class_weight = {0:10, 1:1}\n",
    "                )\n",
    "#maybe write code to generate the best number of epochs and learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d44f4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check the training progress/error by epoch, store in dataframe\n",
    "history = pd.DataFrame(dnn_fit.history)\n",
    "history['epoch'] = dnn_fit.epoch\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b1c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1821e2d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    np.arange(1, 91), \n",
    "    dnn_fit.history['acc'], \n",
    "    label='Accuracy'\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "af277072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 852us/step\n",
      "[[575   0]\n",
      " [234 112]]\n",
      "Accuracy: 0.745928338762215\n"
     ]
    }
   ],
   "source": [
    "#Moving onto predicting\n",
    "dnn_test_pred = dnn_spam_model.predict(testing_features)\n",
    "dnn_pred_classes = [\n",
    "    1 if prob > 0.9993 else 0 for prob in np.ravel(dnn_test_pred)\n",
    "]\n",
    "print(confusion_matrix(testing_classes, dnn_pred_classes))\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(testing_classes, dnn_pred_classes)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095076d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dbb52d2",
   "metadata": {},
   "source": [
    "# Classification GAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ff20b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cheks/opt/anaconda3/lib/python3.9/site-packages/pygam/pygam.py:752: RuntimeWarning: invalid value encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      "/Users/Cheks/opt/anaconda3/lib/python3.9/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return dist.levels/(mu*(dist.levels - mu))\n",
      "/Users/Cheks/opt/anaconda3/lib/python3.9/site-packages/pygam/pygam.py:591: RuntimeWarning: invalid value encountered in multiply\n",
      "  return sp.sparse.diags((self.link.gradient(mu, self.distribution)**2 *\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticGAM(callbacks=[Deviance(), Diffs(), Accuracy()], \n",
       "   fit_intercept=True, max_iter=100, \n",
       "   terms=s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9) + s(10) + s(11) + s(12) + s(13) + s(14) + s(15) + s(16) + s(17) + s(18) + s(19) + s(20) + s(21) + s(22) + s(23) + s(24) + s(25) + s(26) + s(27) + s(28) + s(29) + s(30) + s(31) + s(32) + s(33) + s(34) + s(35) + s(36) + s(37) + s(38) + s(39) + s(40) + s(41) + s(42) + s(43) + s(44) + s(45) + s(46) + s(47) + s(48) + s(49) + s(50) + s(51) + s(52) + s(53) + s(54) + s(55) + s(56) + intercept,\n",
       "   tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticGAM()\n",
    "classifier.fit(training_features, training_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05371434",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1q/8vymbqss1bgdgr4kvck49gtw0000gn/T/ipykernel_12702/873327493.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgam_pred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgam_pred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_classes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_classes' is not defined"
     ]
    }
   ],
   "source": [
    "gam_pred_classes = classifier.predict(testing_features)\n",
    "gam_pred_classes = pred_classes * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9beda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54837215",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(testing_classes, gam_pred_classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
